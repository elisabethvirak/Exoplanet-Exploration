{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (from scikit-learn->sklearn) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\elisa\\anaconda3\\envs\\pythondata\\lib\\site-packages (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import MinMaxScaler to scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import LogisticRegression for model1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import KNeighborsClassifier for model2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import for decision tree for model3\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>1.846000e-04</td>\n",
       "      <td>-1.846000e-04</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-152</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>-1.160000e-07</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>-166</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>...</td>\n",
       "      <td>-220</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>2.430000e-06</td>\n",
       "      <td>-2.430000e-06</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>6.360000e-05</td>\n",
       "      <td>-6.360000e-05</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>-225</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0          CONFIRMED              0              0              0   \n",
       "1     FALSE POSITIVE              0              1              0   \n",
       "2     FALSE POSITIVE              0              1              0   \n",
       "3          CONFIRMED              0              0              0   \n",
       "4          CONFIRMED              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "6986  FALSE POSITIVE              0              0              0   \n",
       "6987  FALSE POSITIVE              0              1              1   \n",
       "6988       CANDIDATE              0              0              0   \n",
       "6989  FALSE POSITIVE              0              0              1   \n",
       "6990  FALSE POSITIVE              0              0              1   \n",
       "\n",
       "      koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  \\\n",
       "0                 0   54.418383     2.479000e-04    -2.479000e-04   \n",
       "1                 0   19.899140     1.490000e-05    -1.490000e-05   \n",
       "2                 0    1.736952     2.630000e-07    -2.630000e-07   \n",
       "3                 0    2.525592     3.760000e-06    -3.760000e-06   \n",
       "4                 0    4.134435     1.050000e-05    -1.050000e-05   \n",
       "...             ...         ...              ...              ...   \n",
       "6986              1    8.589871     1.846000e-04    -1.846000e-04   \n",
       "6987              0    0.527699     1.160000e-07    -1.160000e-07   \n",
       "6988              0    1.739849     1.780000e-05    -1.780000e-05   \n",
       "6989              0    0.681402     2.430000e-06    -2.430000e-06   \n",
       "6990              1    4.856035     6.360000e-05    -6.360000e-05   \n",
       "\n",
       "      koi_time0bk  koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  \\\n",
       "0      162.513840          0.003520  ...             -81      4.467   \n",
       "1      175.850252          0.000581  ...            -176      4.544   \n",
       "2      170.307565          0.000115  ...            -174      4.564   \n",
       "3      171.595550          0.001130  ...            -211      4.438   \n",
       "4      172.979370          0.001900  ...            -232      4.486   \n",
       "...           ...               ...  ...             ...        ...   \n",
       "6986   132.016100          0.015700  ...            -152      4.296   \n",
       "6987   131.705093          0.000170  ...            -166      4.529   \n",
       "6988   133.001270          0.007690  ...            -220      4.444   \n",
       "6989   132.181750          0.002850  ...            -236      4.447   \n",
       "6990   135.993300          0.010800  ...            -225      4.385   \n",
       "\n",
       "      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n",
       "0              0.064          -0.096     0.927          0.105         -0.061   \n",
       "1              0.044          -0.176     0.868          0.233         -0.078   \n",
       "2              0.053          -0.168     0.791          0.201         -0.067   \n",
       "3              0.070          -0.210     1.046          0.334         -0.133   \n",
       "4              0.054          -0.229     0.972          0.315         -0.105   \n",
       "...              ...             ...       ...            ...            ...   \n",
       "6986           0.231          -0.189     1.088          0.313         -0.228   \n",
       "6987           0.035          -0.196     0.903          0.237         -0.079   \n",
       "6988           0.056          -0.224     1.031          0.341         -0.114   \n",
       "6989           0.056          -0.224     1.041          0.341         -0.114   \n",
       "6990           0.054          -0.216     1.193          0.410         -0.137   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "0     291.93423  48.141651      15.347  \n",
       "1     297.00482  48.134129      15.436  \n",
       "2     285.53461  48.285210      15.597  \n",
       "3     288.75488  48.226200      15.509  \n",
       "4     296.28613  48.224670      15.714  \n",
       "...         ...        ...         ...  \n",
       "6986  298.74921  46.973351      14.478  \n",
       "6987  297.18875  47.093819      14.082  \n",
       "6988  286.50937  47.163219      14.757  \n",
       "6989  294.16489  47.176281      15.385  \n",
       "6990  297.00977  47.121021      14.826  \n",
       "\n",
       "[6991 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "koi_ft = df[['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec','koi_period','dec','koi_kepmag','koi_slogg','koi_impact']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X and y values\n",
    "X = koi_ft.drop('koi_disposition',axis=1)\n",
    "y = koi_ft['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create test and train sets of data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.689108</td>\n",
       "      <td>41.830421</td>\n",
       "      <td>17.131</td>\n",
       "      <td>5.274</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.193574</td>\n",
       "      <td>43.461208</td>\n",
       "      <td>12.487</td>\n",
       "      <td>4.239</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.106570</td>\n",
       "      <td>42.150551</td>\n",
       "      <td>14.582</td>\n",
       "      <td>4.387</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.633454</td>\n",
       "      <td>44.161045</td>\n",
       "      <td>12.179</td>\n",
       "      <td>4.372</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.425336</td>\n",
       "      <td>40.506771</td>\n",
       "      <td>15.539</td>\n",
       "      <td>4.541</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "4269              0              0              0              0    8.689108   \n",
       "1188              0              0              0              0   89.193574   \n",
       "4436              0              1              0              1    1.106570   \n",
       "6517              0              0              1              0    1.633454   \n",
       "5077              1              0              1              1   12.425336   \n",
       "\n",
       "            dec  koi_kepmag  koi_slogg  koi_impact  \n",
       "4269  41.830421      17.131      5.274       0.049  \n",
       "1188  43.461208      12.487      4.239       0.015  \n",
       "4436  42.150551      14.582      4.387       0.263  \n",
       "6517  44.161045      12.179      4.372       1.190  \n",
       "5077  40.506771      15.539      4.541       0.966  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data using MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elisa\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7846652679763494\n",
      "Testing Data Score: 0.8020594965675057\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['CONFIRMED' 'FALSE POSITIVE' 'FALSE POSITIVE' 'FALSE POSITIVE'\n",
      " 'FALSE POSITIVE' 'CONFIRMED' 'CONFIRMED' 'CANDIDATE' 'CANDIDATE'\n",
      " 'FALSE POSITIVE']\n",
      "First 10 Actual labels: ['CONFIRMED', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'CONFIRMED', 'CONFIRMED', 'CANDIDATE', 'CANDIDATE', 'FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(3, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "plt.plot(range(3,20,2), train_scores)\n",
    "plt.plot(range(3,20,2), test_scores)\n",
    "plt.xlabel(\"K Neighbors\")\n",
    "plt.ylabel(\"Testing Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=15 Test Acc: 0.797\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=15 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8117489986648865\n",
      "Test score: 0.8094965675057209\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "print('Train score: {}'.format(clf.score(X_train_scaled, y_train)))\n",
    "print('Test score: {}'.format(clf.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232265446224256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=45)\n",
    "rf = rf.fit(X_train_scaled, y_train)\n",
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.18690586589861977, 'koi_fpflag_ss'),\n",
       " (0.14688492948940357, 'koi_fpflag_nt'),\n",
       " (0.1291179292483777, 'koi_fpflag_co'),\n",
       " (0.12329665743033705, 'koi_period'),\n",
       " (0.11256847246346455, 'koi_impact'),\n",
       " (0.09048326069539703, 'koi_slogg'),\n",
       " (0.08345513365954786, 'koi_kepmag'),\n",
       " (0.07934715172514543, 'dec'),\n",
       " (0.04794059938970706, 'koi_fpflag_ec')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, X), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.8232265446224256\n"
     ]
    }
   ],
   "source": [
    "# Best Model Score\n",
    "print(f\"Training Data Score: {rf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "param_grid = {'n_estimators':[100,200,300,400,500],\n",
    "             'min_samples_leaf':[1,2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] min_samples_leaf=1, n_estimators=100 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=1, n_estimators=100, score=0.806, total=   0.7s\n",
      "[CV] min_samples_leaf=1, n_estimators=100 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=1, n_estimators=100, score=0.825, total=   0.7s\n",
      "[CV] min_samples_leaf=1, n_estimators=100 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=1, n_estimators=100, score=0.812, total=   0.7s\n",
      "[CV] min_samples_leaf=1, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=100, score=0.776, total=   0.6s\n",
      "[CV] min_samples_leaf=1, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=100, score=0.808, total=   0.6s\n",
      "[CV] min_samples_leaf=1, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=200, score=0.807, total=   1.3s\n",
      "[CV] min_samples_leaf=1, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=200, score=0.814, total=   1.3s\n",
      "[CV] min_samples_leaf=1, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=200, score=0.819, total=   1.3s\n",
      "[CV] min_samples_leaf=1, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=200, score=0.792, total=   1.3s\n",
      "[CV] min_samples_leaf=1, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=200, score=0.811, total=   1.3s\n",
      "[CV] min_samples_leaf=1, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=300, score=0.812, total=   2.0s\n",
      "[CV] min_samples_leaf=1, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=300, score=0.821, total=   2.0s\n",
      "[CV] min_samples_leaf=1, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=300, score=0.815, total=   2.0s\n",
      "[CV] min_samples_leaf=1, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=300, score=0.786, total=   1.9s\n",
      "[CV] min_samples_leaf=1, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=300, score=0.806, total=   1.9s\n",
      "[CV] min_samples_leaf=1, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=400, score=0.809, total=   2.6s\n",
      "[CV] min_samples_leaf=1, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=400, score=0.813, total=   2.7s\n",
      "[CV] min_samples_leaf=1, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=400, score=0.818, total=   2.6s\n",
      "[CV] min_samples_leaf=1, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=400, score=0.783, total=   2.6s\n",
      "[CV] min_samples_leaf=1, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=400, score=0.811, total=   2.6s\n",
      "[CV] min_samples_leaf=1, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=500, score=0.808, total=   3.2s\n",
      "[CV] min_samples_leaf=1, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=500, score=0.819, total=   3.2s\n",
      "[CV] min_samples_leaf=1, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=500, score=0.815, total=   3.2s\n",
      "[CV] min_samples_leaf=1, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=500, score=0.788, total=   3.2s\n",
      "[CV] min_samples_leaf=1, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=1, n_estimators=500, score=0.801, total=   3.2s\n",
      "[CV] min_samples_leaf=2, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=100, score=0.814, total=   0.6s\n",
      "[CV] min_samples_leaf=2, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=100, score=0.815, total=   0.6s\n",
      "[CV] min_samples_leaf=2, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=100, score=0.811, total=   0.6s\n",
      "[CV] min_samples_leaf=2, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=100, score=0.794, total=   0.6s\n",
      "[CV] min_samples_leaf=2, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=100, score=0.806, total=   0.6s\n",
      "[CV] min_samples_leaf=2, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=200, score=0.810, total=   1.2s\n",
      "[CV] min_samples_leaf=2, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=200, score=0.815, total=   1.3s\n",
      "[CV] min_samples_leaf=2, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=200, score=0.827, total=   1.3s\n",
      "[CV] min_samples_leaf=2, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=200, score=0.783, total=   1.2s\n",
      "[CV] min_samples_leaf=2, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=200, score=0.810, total=   1.3s\n",
      "[CV] min_samples_leaf=2, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=300, score=0.815, total=   1.9s\n",
      "[CV] min_samples_leaf=2, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=300, score=0.824, total=   1.9s\n",
      "[CV] min_samples_leaf=2, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=300, score=0.822, total=   1.9s\n",
      "[CV] min_samples_leaf=2, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=300, score=0.788, total=   1.9s\n",
      "[CV] min_samples_leaf=2, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=300, score=0.807, total=   1.8s\n",
      "[CV] min_samples_leaf=2, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=400, score=0.815, total=   2.5s\n",
      "[CV] min_samples_leaf=2, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=400, score=0.818, total=   2.5s\n",
      "[CV] min_samples_leaf=2, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=400, score=0.813, total=   2.6s\n",
      "[CV] min_samples_leaf=2, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=400, score=0.785, total=   2.5s\n",
      "[CV] min_samples_leaf=2, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=400, score=0.808, total=   2.5s\n",
      "[CV] min_samples_leaf=2, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=500, score=0.810, total=   3.1s\n",
      "[CV] min_samples_leaf=2, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=500, score=0.820, total=   3.1s\n",
      "[CV] min_samples_leaf=2, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=500, score=0.818, total=   3.1s\n",
      "[CV] min_samples_leaf=2, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=500, score=0.791, total=   3.1s\n",
      "[CV] min_samples_leaf=2, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=2, n_estimators=500, score=0.807, total=   3.1s\n",
      "[CV] min_samples_leaf=3, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=100, score=0.803, total=   0.6s\n",
      "[CV] min_samples_leaf=3, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=100, score=0.817, total=   0.6s\n",
      "[CV] min_samples_leaf=3, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=100, score=0.827, total=   0.6s\n",
      "[CV] min_samples_leaf=3, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=100, score=0.782, total=   0.6s\n",
      "[CV] min_samples_leaf=3, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=100, score=0.797, total=   0.6s\n",
      "[CV] min_samples_leaf=3, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=200, score=0.812, total=   1.3s\n",
      "[CV] min_samples_leaf=3, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=200, score=0.825, total=   1.3s\n",
      "[CV] min_samples_leaf=3, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=200, score=0.824, total=   1.2s\n",
      "[CV] min_samples_leaf=3, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=200, score=0.788, total=   1.2s\n",
      "[CV] min_samples_leaf=3, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=200, score=0.803, total=   1.2s\n",
      "[CV] min_samples_leaf=3, n_estimators=300 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=3, n_estimators=300, score=0.811, total=   1.8s\n",
      "[CV] min_samples_leaf=3, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=300, score=0.820, total=   1.8s\n",
      "[CV] min_samples_leaf=3, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=300, score=0.827, total=   1.8s\n",
      "[CV] min_samples_leaf=3, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=300, score=0.791, total=   2.0s\n",
      "[CV] min_samples_leaf=3, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=300, score=0.807, total=   1.8s\n",
      "[CV] min_samples_leaf=3, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=400, score=0.816, total=   2.5s\n",
      "[CV] min_samples_leaf=3, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=400, score=0.824, total=   2.5s\n",
      "[CV] min_samples_leaf=3, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=400, score=0.822, total=   2.5s\n",
      "[CV] min_samples_leaf=3, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=400, score=0.785, total=   2.5s\n",
      "[CV] min_samples_leaf=3, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=400, score=0.811, total=   2.4s\n",
      "[CV] min_samples_leaf=3, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=500, score=0.817, total=   3.1s\n",
      "[CV] min_samples_leaf=3, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=500, score=0.824, total=   3.1s\n",
      "[CV] min_samples_leaf=3, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=500, score=0.817, total=   3.1s\n",
      "[CV] min_samples_leaf=3, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=500, score=0.786, total=   3.1s\n",
      "[CV] min_samples_leaf=3, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=3, n_estimators=500, score=0.810, total=   3.1s\n",
      "[CV] min_samples_leaf=4, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=100, score=0.820, total=   0.6s\n",
      "[CV] min_samples_leaf=4, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=100, score=0.825, total=   0.6s\n",
      "[CV] min_samples_leaf=4, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=100, score=0.811, total=   0.6s\n",
      "[CV] min_samples_leaf=4, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=100, score=0.785, total=   0.6s\n",
      "[CV] min_samples_leaf=4, n_estimators=100 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=100, score=0.807, total=   0.6s\n",
      "[CV] min_samples_leaf=4, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=200, score=0.814, total=   1.2s\n",
      "[CV] min_samples_leaf=4, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=200, score=0.822, total=   1.2s\n",
      "[CV] min_samples_leaf=4, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=200, score=0.817, total=   1.2s\n",
      "[CV] min_samples_leaf=4, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=200, score=0.792, total=   1.2s\n",
      "[CV] min_samples_leaf=4, n_estimators=200 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=200, score=0.804, total=   1.2s\n",
      "[CV] min_samples_leaf=4, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=300, score=0.820, total=   1.8s\n",
      "[CV] min_samples_leaf=4, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=300, score=0.820, total=   1.8s\n",
      "[CV] min_samples_leaf=4, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=300, score=0.820, total=   1.8s\n",
      "[CV] min_samples_leaf=4, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=300, score=0.785, total=   1.7s\n",
      "[CV] min_samples_leaf=4, n_estimators=300 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=300, score=0.805, total=   1.8s\n",
      "[CV] min_samples_leaf=4, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=400, score=0.821, total=   2.3s\n",
      "[CV] min_samples_leaf=4, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=400, score=0.822, total=   2.4s\n",
      "[CV] min_samples_leaf=4, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=400, score=0.818, total=   2.4s\n",
      "[CV] min_samples_leaf=4, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=400, score=0.779, total=   2.4s\n",
      "[CV] min_samples_leaf=4, n_estimators=400 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=400, score=0.811, total=   2.4s\n",
      "[CV] min_samples_leaf=4, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=500, score=0.814, total=   3.0s\n",
      "[CV] min_samples_leaf=4, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=500, score=0.820, total=   3.0s\n",
      "[CV] min_samples_leaf=4, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=500, score=0.826, total=   3.0s\n",
      "[CV] min_samples_leaf=4, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=500, score=0.783, total=   2.9s\n",
      "[CV] min_samples_leaf=4, n_estimators=500 ............................\n",
      "[CV]  min_samples_leaf=4, n_estimators=500, score=0.804, total=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_leaf': [1, 2, 3, 4],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 3, 'n_estimators': 400}\n",
      "0.8115531695034894\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.67      0.59      0.63       401\n",
      "     CONFIRMED       0.67      0.72      0.69       456\n",
      "FALSE POSITIVE       0.99      1.00      0.99       891\n",
      "\n",
      "      accuracy                           0.83      1748\n",
      "     macro avg       0.78      0.77      0.77      1748\n",
      "  weighted avg       0.83      0.83      0.83      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elisabethVirak_original.sav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'elisabethVirak_original.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
